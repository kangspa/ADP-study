# ADP-study

<https://www.dataq.or.kr/www/sub/a_05.do>

데이터분석 전문가란 데이터 이해 및 처리 기술에 대한 기본지식을 바탕으로 데이터분석 기획, 데이터분석, 데이터 시각화 업무를 수행하고 이를 통해 프로세스 혁신 및 마케팅 전략 결정 등의 과학적 의사결정을 지원하는 직무를 수행하는 전문가를 말한다.

# 필기시험 출제 문항
1. **데이터의 이해** (10문항 / 1점)
    - 데이터의 이해
    - 데이터의 가치와 미래
    - 가치 창조를 위한 데이터 사이언스와 전략 인사이트
2. **데이터 처리 기술 이해** (10문항 / 1점)
    - 데이터 처리 프로세스
    - 데이터 처리 기술
3. **데이터 분석 기획** (10문항 / 1점)
    - 데이터 분석 기획의 이해
    - 분석 마스터 플랜
4. **데이터 분석** (40문항 / 1점)
    - R 기초와 데이터 마트
    - 통계분석
    - 정형 데이터 마이닝
    - 비정형 데이터 마이닝
5. **데이터 시각화** (10문항 / 1점)
    - 시각화 인사이트 프로세스
    - 시각화 디자인
    - 시각화 구현

＋ 서술형 (1문항 / 20점)

- 총 180분

# 실기시험 출제 문항
**데이터분석 실무** (240분)
- 필기 합격 후 2년 이내 응시해야함.

# 합격기준
- 필기합격 : 총점 100점 기준 70점 이상
    - 과락 : 과목별 40% 미만 취득
- 실기합격 : 실기 총점 100점 기준 75점 이상
- 최종합격 : 응시자격심의 서류 통과자

# 과목 및 내용
데이터분석 전문가 자격검정 시험의 과목은 총 5과목으로 구성되어 있으며 데이터 이해 과목을 바탕으로 데이터분석 기획, 데이터분석, 데이터 시각화를 수행하는 능력을 검정한다.

## 필기

### 데이터 이해

1. 데이터의 이해
    - 데이터와 정보
    - 데이터베이스의 정의와 특징
    - 데이터베이스 활용
2. 데이터의 가치와 미래
    - 빅데이터의 이해
    - 빅데이터의 가치와 영향
    - 비즈니스 모델
    - 위기 요인과 통제 방안
    - 미래의 빅데이터
3. 가치 창조를 위한 데이터 사이언스와 전략 인사이트
    - 빅데이터분석과 전략 인사이트
    - 전략 인사이트 도출을 위한 필요 역량
    - 빅데이터 그리고 데이터 사이언스의 미래

### 데이터 처리 기술 이해

1. 데이터 처리 프로세스
    - ETL(Extraction, Transformation and Load)
    - CDC(Change Data Capture)
    - EAI(Enterprise Application Integration)
    - 데이터 연계 및 통합 기법 요약
    - 대용량 비정형 데이터 처리
2. 데이터 처리 기술
    - 분산 데이터 저장 기술
    - 분산 컴퓨팅 기술
    - 클라우드 인프라 기술

### 데이터분석 기획

1. 데이터분석 기획의 이해
    - 분석 기획 방향성 도출
    - 분석 방법론
    - 분석 과제 발굴
    - 분석 프로젝트 관리 방안
2. 분석 마스터 플랜
    - 마스터 플랜 수립
    - 분석 거버넌스 체계 수립

### 데이터분석

1. R기초와 데이터 마트
    - R기초
    - 데이터 마트
    - 결측값 처리와 이상값 검색
2. 통계분석
    - 통계학 개론
    - 기초 통계분석
    - 다변량 분석
    - 시계열 예측
3. 정형 데이터 마이닝
    - 데이터 마이닝 개요
    - 분류분석(Classification)
    - 군집분석(Clustering)
    - 연관분석(Association Analysis)
4. 비정형 데이터 마이닝
    - 텍스트 마이닝
    - 사회연결망 분석

### 데이터 시각화

1. 시각화 인사이트 프로세스
    - 시각화 인사이트 프로세스의 의미
    - 탐색(1단계)
    - 분석(2단계)
    - 활용(3단계)
2. 시각화 디자인
    - 시각화의 정의
    - 시각화 프로세스
    - 시각화 방법
    - 빅데이터와 시각화 디자인
3. 시각화 구현
    - 시각화 구현 개요
    - 분석 도구를 이용한 시각화 구현
    - 라이브러리 기반의 시각화 구현: D3.js

## 실기

1. 주요 내용 : 데이터분석 실무
2. 출제 방향 : 기계학습 영역과 통계 영역으로 출제된다.

### 기계학습

기계학습 영역은 ‘기계학습 알고리즘을 활용한 분석’, ‘통계적 학습 방법을 활용한 분석’을 포괄하며, 데이터 전처리 및 탐색적 데이터 분석, 모델링 및 결과 해석 과정을 포함한다.

#### [기계학습 알고리즘을 활용한 분석]

**유형1** : 데이터 전처리
결측값 처리, 이상값 탐지 및 수정, 데이터 정규화, 파생 변수 생성, 데이터 샘플링, 데이터 병합 및 분할 작업 등 데이터의 질을 향상시키고 모델링에 적합한 형태로 변환하는 작업이 포함된다.

**유형2** : 탐색적 데이터 분석(EDA)
요약 통계량 계산을 통한 기초 통계 분석, 히스토그램, 산점도, 상자그림 등을 이용한 데이터 시각화, 주요 변수 간의 관계 분석, 차원 축소 기법, 군집 분석 등을 통해 데이터의 분포 및 군집 구조를 파악하고 주요 패턴을 도출하는 작업이 포함된다.

**유형3** : 기계학습 알고리즘을 활용한 모델 구축
회귀, 분류, 군집화 등의 다양한 분석 기법을 선택하여 적용하고, 초매개변수(hyperparameter) 조율을 통해 모델 성능을 최적화하는 작업이 포함된다.

**유형4** : 구축한 모델을 평가하고 최적의 모델을 선택
다양한 지표로 모델 성능을 평가하고 결과를 해석하여, 최적의 모델을 선정하는 등의 작업이 포함된다.

#### [통계적 학습 방법을 활용한 분석]

**유형1** : 데이터 품질 평가 및 변수 선택·처리
이상값 및 결측값 처리, 변수 구성 및 기초통계량 산출, 연속형 및 범주형 변수에 대한 기초적인 통계 검정 등 데이터 품질을 평가하고 변수를 적절하게 처리하는 작업이 포함된다.

**유형2** : 변수 간 관계 분석 및 예측 모델 구축
독립변수와 종속변수 간의 관계를 통계적 기법을 통해 분석하고, 데이터를 변형하여 모델 성능을 향상시키며, 그 결과를 통해 유의미한 통찰을 도출하는 작업이 포함된다.

**유형3** : 통계적 학습 방법 및 기계학습 방법을 사용한 모델 구축
통계적 학습 방법과 기계학습 방법으로 모델을 구축하여 각 방법론을 비교하고 최적의 모델을 선정하는 등의 작업이 포함된다.

### 통계

통계 영역은 ‘데이터 탐색 및 기초 통계 분석’,‘통계적 추론 및 통계 모형 구축’등을 포괄한다.

#### [데이터 탐색 및 기초 통계 분석]

**유형1** : 기술통계량 계산 및 시각화
평균, 중앙값, 분산 표준편차 등의 기술 통계량을 계산하고, 히스토그램, 산점도, 상자그림 등 시각화 기법을 사용하여 데이터의 분포, 이상값, 패턴 등을 시각적으로 표현하는 등의 작업이 포함된다.

**유형2** : 탐색적 데이터 분석(EDA) 및 데이터 전처리
EDA 과정에서 결측값 처리, 이상값 수정, 변수 변환 및 파생 변수 생성 등의 전처리 작업을 통해 데이터를 분석 및 준비하는 등의 작업이 포함된다.

#### [통계적 추론 및 통계 모형 구축]

**유형1** : 통계적 유의성 검정
가설 검정 기법을 사용하여 데이터의 통계적 유의성을 검정하고, 신뢰 구간을 계산하여 데이터의 불확실성을 평가하는 등의 작업이 포함된다.

**유형2** : 상관 분석 및 회귀 분석
상관 분석을 통해 변수 간의 연관성을 파악하고, 단순 및 다중 선형 회귀, 로지스틱 회귀, 비선형 회귀 모델 등을 구축하여 데이터 간의 관계를 분석하고 예측 모델을 평가하는 작업이 포함된다.

**유형3** : 다변량 분석
고차원 데이터에서 중요한 정보를 추출하고 데이터의 차원을 축소하거나 변수 간의 관계를 분석하고, 그룹 간의 차이를 분석·분류하여 군집화하는 등의 작업이 포함된다.

**유형4** : 시계열 분석
시계열 데이터를 분석하여 추세, 계절성, 변동성을 반영하는 예측 모델 구축 및 미래 데이터를 예측하고, 데이터를 시각화하며, 적절한 모델을 사용해 예측 성능을 평가하는 작업이 포함된다.

**유형5** : 고급 통계 분석
고급 통계 기법을 선택·적용하여 데이터의 특성을 분석하고, 도출된 결과를 해석하는 등의 작업이 포함된다.

### 고려사항

데이터 분석 실기 문제의 답안을 작성할 때는 다음의 사항에 유의해야 한다.

1. **명확한 표현과 논리적 전개**
    답안은 주어진 문제에 대한 핵심 내용만을 명확하고 간결하게 작성하며, 분석 과정과 결론에 일관성이 있어야 한다. 해당 문제와 관련된 분석 방법론과 데이터 특성을 반영하여 논리적으로 전개해야 하며, 이해하기 쉽게 작성되었는지 검토한다.
2. **분석 절차와 코드 서술**
    데이터 전처리, 모델링, 검정 절차 등 분석 과정의 각 단계와 관련된 코드를 간결하게 정리하여 제출한다. 코드의 효율성과 정확성을 유지하며, 주요 부분에 대해 주석을 통해 설명을 추가하고, 코드의 각 부분이 해당 문제 풀이에 어떻게 연결되는지를 명확히 나타낸다.
3. **데이터 전처리와 탐색적 분석(EDA)**
    데이터 전처리 과정에서 수행한 결측값 처리, 이상값 수정, 변수 변환 등의 작업 내용을 기술하고 해당 과정이 분석에 미친 영향 등을 설명한다. 탐색적 데이터 분석 결과는 시각화 자료와 함께 제시하고 파악된 데이터의 기본 특성 등을 설명한다.
4. **모델 선택**
    사용한 분석 기법 또는 모델을 선택한 이유와 그 과정에서 고려한 대안들을 서술하고, 선택한 모델이 문제 해결에 어떻게 기여했는지 논리적으로 설명한다. 다양한 모델 중에서 선택한 이유와 해당 모델의 강점, 잠재적 한계점 등을 명확히 기술하며, 다른 방법들과의 비교를 통해 선택의 정당성을 입증한다.
5. **결과 해석**
    분석 결과의 실질적 유용성을 바탕으로 최종 결론을 도출하고 분석 내용을 종합적으로 요약하며, 추가적인 제언 등을 기술한다.

# 실기 시험 환경 구성하기

- 참고 : <https://well-being-stat.tistory.com/2>

1. conda 가상 환경을 아래와 같이 생성
    ```bash
    conda create -n ADP-study python=3.7
    ```
2. `ADP-study` 환경 실행
    ```bash
    conda activate ADP-study
    ```
3. 주피터 노트북을 `conda` 명령어로 설치
    ```bash
    conda install jupyter
    ```
4. 충돌 방지를 위해, 필수 패키지를 우선 아래와 같이 설치
    ```bash
    pip install -r key-requirements.txt
    ```
5. 시험장과 동일한 환경 구성
    ```bash
    for /F "tokens=*" %i in (35-linux-pck.txt) do @pip show %i.split("==")[0] 2>NUL || pip install --no-deps %i
    ```
    - window 환경이라서 그런건지, conda로 가상환경 구축해서 그런건지, `pip install -r 35-linux-pck.txt` 로 설치 진행 시 에러 발생하여 라인별로 read 후 설치 진행
        - conda 환경 없이 설치 진행한다면, python 3.7을 별도로 설치하고 환경 변수 설정 후 진행해야하여 그냥 conda로 진행
    - 제35회 ADP 실기 시험 환경 라이브러리, 해당 환경은 리눅스라고 함
        - 완벽하게 구성하고 싶다면 WSL 이용해서 리눅스 환경에서 진행하는 것을 추천
    
    ```bash
    while IFS= read -r l; do p="${l%%==*}"; pip show "$p" >/dev/null 2>&1 || pip install --no-deps "$l"; done < 35_pck_list.txt
    ```
    - wsl 환경에서는 위와 같이 명령어 입력해서 설치 진행
    - 왜인지 `pip install -r 30_pck_list.txt`로 진행할 경우 더 높은 파이썬 버전을 요구한다는 에러와 함께 설치 진행 불가
        - 위와 같은 명령어로 하나씩 설치 진행하지만, 동일하게 에러 발생하는 라이브러리가 몇 존재
        - 주피터 노트북 실행하는 것까지 생각하면 그냥 miniconda로 진행하는게 더 좋을 것으로 보임
6. `jupyter notebook` 통해서 주피터 노트북 실행 가능
    - 시스템 검색에 jupyuter notebook 검색 시, 나오는 걸로 실행 가능하다고 함 (내 경우는 안 됨)