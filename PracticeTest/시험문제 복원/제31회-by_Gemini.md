# ADP 31회 실기 문제 풀이 by Gemini

본 문서는 "제31회.md" 파일에 제시된 문제들에 대한 분석 방법론과 풀이 과정을 상세히 설명합니다. 각 문제에 대해 가능한 여러 분석 방법을 소개하고, 실제 문제에 적용하는 과정을 코드 예제와 함께 제시합니다.

---

## 1번 문제: 데이터 탐색 및 전처리 (비만도 데이터)

### 1-1. EDA & 결측치 및 이상치 판단과 처리

- **EDA (탐색적 데이터 분석)**
    - `df.info()`로 데이터 타입과 결측치 유무를 확인합니다. `df.describe()`로 숫자형 변수의 통계치를 파악합니다.
    - `sns.countplot(y='NObeyesdad')`로 종속변수의 클래스 분포를 확인하여 데이터 불균형 여부를 점검합니다.
    - `sns.boxplot`으로 `Age`, `Height`, `Weight` 등 숫자형 변수의 이상치를 시각적으로 확인합니다.
    - 데이터셋이 "cleaned and data synthetic"으로 명시되어 있으므로, 심각한 결측치나 이상치는 없을 가능성이 높지만, 확인 과정은 필수적입니다.

- **결측치 및 이상치 처리**
    - **결측치**: 만약 결측치가 발견된다면, 변수의 중요도와 결측치의 비율에 따라 처리합니다. 소수의 결측치는 숫자형 변수의 경우 중앙값(median), 범주형 변수의 경우 최빈값(mode)으로 대치하는 것이 일반적입니다.
    - **이상치**: Boxplot 등에서 발견된 극단적인 값은 모델 성능에 악영향을 줄 수 있습니다. IQR Rule을 사용하여 정상 범위를 벗어나는 값을 탐지하고, 데이터의 손실을 막기 위해 해당 값을 상/하한값으로 대체(Capping)하는 방법을 적용할 수 있습니다.

### 1-2. 데이터 전처리 기법 2가지 설명 및 적용 효과

1.  **범주형 변수 인코딩 (Categorical Variable Encoding)**
    - **설명**: 머신러닝 모델은 숫자형 데이터만 처리할 수 있으므로, `Gender`, `FAVC`, `MTRANS` 등 문자열로 된 범주형 변수를 숫자형으로 변환하는 과정입니다. 변수의 특성에 따라 **순서형 인코딩(Ordinal Encoding)**이나 **명목형 인코딩(One-Hot Encoding)**을 사용합니다.
    - **적용 효과**: 이 데이터셋에는 순서가 있는 변수(`FCVC`, `CAEC` 등)와 순서가 없는 명목형 변수(`Gender`, `MTRANS` 등)가 혼재합니다. 각 변수의 특성에 맞게 인코딩을 적용하면, 모델이 변수 간의 관계를 올바르게 학습할 수 있게 됩니다. 예를 들어, `FCVC`를 `{'Never':0, 'Sometimes':1, 'Always':2}`로 변환하면 '채소 섭취 빈도'라는 순서 정보를 모델에 전달할 수 있습니다.

2.  **피처 스케일링 (Feature Scaling)**
    - **설명**: `Age`, `Height`, `Weight` 등 숫자형 변수들은 서로 다른 단위와 값의 범위를 가집니다. `StandardScaler`나 `MinMaxScaler`를 사용하여 모든 숫자형 변수의 스케일을 통일하는 과정입니다.
    - **적용 효과**: 로지스틱 회귀, SVM, 신경망 등 거리 기반 또는 경사하강법을 사용하는 알고리즘은 변수의 스케일에 민감합니다. 스케일링을 통해 모든 변수가 모델 학습에 동등한 기여를 하도록 만들어, 모델의 수렴 속도를 높이고 전반적인 예측 성능을 향상시키는 효과를 가져옵니다.

### 1-3. 파생변수 1개 생성 및 이유

- **파생변수 생성**: **`Tech_Addiction_Score` (기술 기기 중독 점수)**
    - **생성 방법**: `TUE`(Time using technology devices)와 `FAF`(Physical activity frequency)는 건강과 밀접한 관련이 있습니다. `TUE`는 순서형으로 변환하고(`0 to 2`=0, `3 to 5`=1, `>5`=2), `FAF`도 순서형으로 변환하여(`0`=0, `1 to 2`=1, `2 to 4`=2, `4 to 5`=3), `Tech_Addiction_Score = TUE_encoded - FAF_encoded` 와 같이 계산할 수 있습니다. 즉, 기술 기기 사용 시간이 길고 신체 활동이 적을수록 점수가 높아집니다.
    - **이유**: 비만은 단순히 식습관뿐만 아니라 생활 습관과도 깊은 관련이 있습니다. 특히 현대 사회에서 기술 기기 사용 시간과 신체 활동 부족은 비만의 주요 원인으로 꼽힙니다. 이 두 변수를 조합하여 '정적인 생활 습관'을 나타내는 파생변수를 만들면, 개별 변수만으로는 파악하기 어려운 복합적인 생활 패턴의 영향을 모델이 더 잘 학습하여 예측 성능을 높일 수 있을 것으로 기대됩니다.

---

## 2번 문제: 분류 모델링

### 2-1. 앙상블 제외 분류 모델 3가지 구축 및 비교

- **선정 모델**: 
    1.  **Logistic Regression**: 선형 모델의 기준 성능을 확인하기 위해 선택합니다.
    2.  **K-Nearest Neighbors (KNN)**: 비모수적 모델로, 데이터의 지역적 특성을 기반으로 예측합니다.
    3.  **Support Vector Machine (SVM)**: 강력한 분류 성능을 보이는 모델로, 복잡한 결정 경계를 잘 찾아냅니다.

- **결과 비교**: 1번에서 전처리한 데이터를 사용하여 세 모델을 학습시키고, 테스트 데이터에 대한 **정확도(Accuracy)**와 **F1-Score(weighted)**를 비교합니다. 데이터의 특성에 따라 다르겠지만, 일반적으로 SVM이 복잡한 패턴을 더 잘 학습하여 가장 높은 성능을 보일 가능성이 있습니다. 결과표를 통해 각 모델의 성능을 정량적으로 비교하고, 어떤 모델이 이 데이터셋에 가장 적합한지 설명합니다.

### 2-2. 그리드 서치를 통한 파라미터 튜닝

- **분석 방법**: 2-1에서 선택한 모델 중 하나(예: **SVM**)에 대해 `GridSearchCV`를 사용하여 최적의 하이퍼파라미터를 탐색합니다. SVM의 경우, 비용(C)과 커널 계수(gamma)가 중요한 튜닝 대상입니다.

    ```python
    from sklearn.model_selection import GridSearchCV
    from sklearn.svm import SVC
    from sklearn.metrics import classification_report

    # SVM 모델 및 파라미터 그리드 설정
    svm = SVC(random_state=42)
    param_grid = {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto'], 'kernel': ['rbf']}

    # 그리드 서치 수행
    grid_search = GridSearchCV(svm, param_grid, cv=3, scoring='f1_weighted')
    grid_search.fit(X_train, y_train)

    # 최적 모델로 평가
    best_model = grid_search.best_estimator_
    preds = best_model.predict(X_test)
    print(f"Best Parameters: {grid_search.best_params_}")
    print(classification_report(y_test, preds))
    ```
- **성능 평가**: `classification_report`를 통해 최적화된 모델의 클래스별 `precision`과 `recall`을 확인하고, 전반적인 성능 향상 여부를 분석합니다.

### 2-3. Soft Voting 결과와 비교

- **분석 방법**: 2-1의 세 모델(Logistic Regression, KNN, SVM)을 `VotingClassifier(voting='soft')`를 사용하여 앙상블 모델을 구축합니다. (SVM은 `probability=True`로 설정 필요)
- **결과 비교**: Soft Voting 모델의 F1-Score와 2-2에서 튜닝한 단일 모델(SVM)의 F1-Score를 비교합니다. 일반적으로 여러 모델의 예측 확률을 평균내는 Soft Voting 방식이 단일 모델보다 더 안정적이고 높은 성능을 보이는 경향이 있습니다. 두 모델의 성능 지표를 직접 비교하여 어떤 접근법이 더 우수했는지 결론 내립니다.

---

## 3번 문제: 변수 중요도 분석

### 3-1. Drop Column Importance 구현 및 시각화

- **분석 방법**: 특정 변수를 제외했을 때 모델 성능이 얼마나 저하되는지를 측정하여 해당 변수의 중요도를 평가하는 기법입니다.
    1.  전체 변수를 사용하여 최종 모델(e.g., 2-3의 Soft Voting 모델)을 학습시키고, 기준 성능(e.g., weighted recall)을 측정합니다.
    2.  각 변수를 한 번에 하나씩 제외하면서 모델을 다시 학습시키고 성능을 측정합니다.
    3.  (기준 성능 - 변수 제외 시 성능) 값을 계산하여 '중요도'로 삼습니다. 이 값이 클수록 해당 변수가 중요하다는 의미입니다.
    4.  계산된 중요도를 `barplot`으로 시각화하여 어떤 변수들이 모델 성능에 큰 영향을 미치는지 확인합니다.

---

## 4번 문제: 학생 건강 데이터 분석

### 4-1. 전처리 및 빈도표 생성

- **분석 방법**:
    1.  **BMI 계산**: `몸무게(kg) / (키(m)**2)` 공식을 적용하여 BMI 컬럼을 생성합니다. (키는 cm 단위이므로 100으로 나눠서 사용)
    2.  **만 나이 계산**: `건강검진일`과 `생년월일`을 datetime 객체로 변환하고, 문제의 기준(햇수 16년 + 일수 364일)에 따라 만 16세와 17세로 구분하는 `만나이` 컬럼을 생성합니다.
    3.  **적정 체중 여부**: `만나이`와 `성별`에 따른 BMI 기준을 적용하여 `적정체중여부` 컬럼(True/False 또는 1/0)을 생성합니다.
    4.  **BMI 구간화**: `pd.cut`을 사용하여 BMI 값을 5단위로 구간화합니다.
    5.  **빈도표**: `pd.crosstab`을 사용하여 `BMI구간`과 `적정체중여부` 간의 교차 빈도표를 생성합니다.

### 4-2. 독립성 통계 검정

- **분석 방법**: `적정체중여부`(범주형)와 다른 변수들 간의 독립성을 검정합니다.
    - **vs. 범주형** (`공학여부`, `아침식사여부`, `성별`): **카이제곱 독립성 검정** (`scipy.stats.chi2_contingency`)
    - **vs. 연속형/순서형** (`일주일운동시간`, `채소섭취정도`, `수면시간`): **독립표본 t-검정** (`scipy.stats.ttest_ind`)
- **결과**: 각 검정의 p-value가 유의수준(0.05)보다 작은 변수들을 유의한 변수로 판단합니다.

### 4-3. 모델링 및 해석

- **분석 방법**: 4-2에서 선택된 유의한 변수들만 사용하여 로지스틱 회귀와 XGBoost 모델을 학습시키고, 성능(Accuracy, F1-score 등)을 비교합니다.
- **해석**:
    - **로지스틱 회귀**: `np.exp(model.coef_)`를 통해 **오즈비(Odds Ratio)**를 계산합니다. 오즈비가 1보다 크면 해당 변수가 1 증가할 때 적정 체중일 확률이 높아지고, 1보다 작으면 낮아짐을 의미합니다.
    - **XGBoost**: `model.feature_importances_`를 시각화하여 예측에 가장 큰 영향을 미친 변수를 확인하고 설명합니다.

### 4-4. ROC-AUC 그래프 시각화

- **분석 방법**: `sklearn.metrics.roc_curve`를 사용하여 두 모델의 FPR(False Positive Rate)과 TPR(True Positive Rate)을 계산하고, `matplotlib`을 사용하여 두 ROC 곡선을 하나의 그래프에 겹쳐 그립니다. `sklearn.metrics.auc`로 계산한 AUC 점수를 각 곡선의 범례에 함께 표시하여 성능을 시각적으로 비교합니다.

---

## 5번 문제: 베이즈 추론

- **분석 방법**: 사전분포와 가능도(데이터)를 결합하여 사후분포를 추정하는 베이즈 추론 문제입니다. 정규분포의 평균에 대한 추론 공식을 사용합니다.
- **풀이**: 사후평균 = $\frac{(\frac{1}{\sigma_{prior}^2})\mu_{prior} + (\frac{n}{\sigma_{data}^2})\bar{x}}{(\frac{1}{\sigma_{prior}^2}) + (\frac{n}{\sigma_{data}^2})}$
    - 사전분포: $N(\mu_{prior}=100, \sigma_{prior}^2=256)$
    - 데이터분포: $N(\theta, \sigma_{data}^2=100)$
    - 데이터: $n=1, \bar{x}=120$
    - 위 공식에 값을 대입하여 사후평균을 계산합니다.

---

## 6번 문제: 회귀분석 진단

### 6-1. 유의하지 않은 변수 파악

- **분석 방법**: `statsmodels.api.OLS`를 사용하여 `Sales ~ TV + Radio + Newspaper` 회귀 모델을 학습시키고, `summary()` 결과에서 각 변수의 **p-value(`P>|t|`)**를 확인합니다. p-value가 유의수준(0.05)보다 큰 변수가 통계적으로 유의하지 않은 변수입니다. (이 데이터셋에서는 `Newspaper`가 해당됩니다.)

### 6-2. 변수 선택 시 먼저 제거될 변수

- **제거될 변수**: **Newspaper**
- **근거**: 후진 제거법(Backward Elimination)과 같은 변수 선택 기법에서는 통계적으로 가장 유의하지 않은 변수부터 제거합니다. 6-1의 결과에서 `Newspaper`의 p-value가 가장 높으므로, 모델의 간결성과 성능 개선을 위해 가장 먼저 제거될 대상입니다.

### 6-3. VIF를 통한 다중공선성 진단

- **분석 방법**: **VIF(Variance Inflation Factor, 분산 팽창 요인)**는 한 독립변수가 다른 독립변수들에 의해 얼마나 설명되는지를 나타내는 지표입니다. `statsmodels.stats.outliers_influence.variance_inflation_factor` 함수를 사용하여 각 변수의 VIF를 계산합니다. 일반적으로 VIF가 10 이상이면 다중공선성이 심각하다고 판단합니다.

---

## 7번 문제: 코크란 Q 검정

- **분석 방법**: 3개 이상의 대응표본(동일한 계약에 대한 여러 영업사원의 성사 여부)에 대한 비율(성공률)을 비교하는 것이므로, **코크란의 Q 검정(Cochran's Q test)**을 사용합니다. 이는 맥니마 검정의 확장된 형태입니다.
- **가설**: H0: 모든 영업사원의 계약 성사율은 동일하다. H1: 적어도 한 영업사원의 계약 성사율은 다르다.
- **풀이**: `statsmodels.stats.contingency_tables.cochrans_q`를 사용하여 p-value를 계산하고, 유의수준 0.05와 비교하여 가설 채택 여부를 결정합니다.

---

## 8번 문제: 포아송 분포

- **분석 방법**: 단위 시간(하루)당 평균 발생 횟수($\lambda=2.2$)가 주어진 사건의 발생 횟수에 대한 확률 문제이므로 **포아송 분포**를 사용합니다.

### 8-1. 한 마리도 안 버려질 확률

- **풀이**: $P(X=0)$을 구합니다. `scipy.stats.poisson.pmf(k=0, mu=2.2)`를 사용합니다.

### 8-2. 적어도 2마리가 버려질 확률

- **풀이**: $P(X \ge 2) = 1 - P(X < 2) = 1 - (P(X=0) + P(X=1))$을 계산합니다. `1 - poisson.cdf(k=1, mu=2.2)`를 사용하면 더 간편합니다.
