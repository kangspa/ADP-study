{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f51188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "888de99c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.16\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b17314df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC (RBF Kernel) 정확도: 0.977\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1. 데이터 준비 및 전처리\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# SVC는 스케일링이 매우 중요\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 2. SVC 모델 학습 (RBF 커널)\n",
    "# 주요 하이퍼파라미터\n",
    "# kernel: 커널 종류 ('linear', 'poly', 'rbf', 'sigmoid')\n",
    "# C: 규제 파라미터\n",
    "# gamma: 커널 계수\n",
    "svc_rbf = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "svc_rbf.fit(X_train_scaled, y_train)\n",
    "svc_pred = svc_rbf.predict(X_test_scaled)\n",
    "print(f\"SVC (RBF Kernel) 정확도: {accuracy_score(y_test, svc_pred):.3f}\") # 0.977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "651cd74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GridSearchCV 최적 파라미터 (SVC): {'C': 10, 'gamma': 0.01}\n",
      "최적 파라미터 적용 시 정확도: 0.975 (교차검증 평균)\n",
      "\n",
      "Best SVC 분류 리포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98        64\n",
      "           1       0.99      0.98      0.99       107\n",
      "\n",
      "    accuracy                           0.98       171\n",
      "   macro avg       0.98      0.98      0.98       171\n",
      "weighted avg       0.98      0.98      0.98       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. GridSearchCV를 이용한 최적 하이퍼파라미터 탐색\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "grid_svc = GridSearchCV(SVC(kernel='rbf', random_state=42), param_grid, cv=5, scoring='accuracy', n_jobs=1)\n",
    "grid_svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\nGridSearchCV 최적 파라미터 (SVC):\", grid_svc.best_params_) # {'C': 10, 'gamma': 0.01}\n",
    "print(f\"최적 파라미터 적용 시 정확도: {grid_svc.best_score_:.3f} (교차검증 평균)\") # 0.975\n",
    "\n",
    "# 최적 모델로 예측 및 평가\n",
    "best_svc = grid_svc.best_estimator_\n",
    "best_pred = best_svc.predict(X_test_scaled)\n",
    "print(\"\\nBest SVC 분류 리포트:\\n\", classification_report(y_test, best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd96d784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting 정확도: 0.956\n",
      "XGBoost 정확도: 0.956\n",
      "LightGBM 정확도: 0.956\n",
      "\n",
      "XGBoost (Early Stopping) 정확도: 0.939\n",
      "XGBoost (Early Stopping) AUC: 0.990\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# 1. 데이터 준비\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 2. 그래디언트 부스팅 (Scikit-learn)\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "gb_pred = gb_clf.predict(X_test)\n",
    "print(f\"Gradient Boosting 정확도: {accuracy_score(y_test, gb_pred):.3f}\") # 0.956\n",
    "\n",
    "# 3. XGBoost\n",
    "# !pip install xgboost\n",
    "import xgboost as xgb\n",
    "# 이진 분류의 경우, objective='binary:logistic'\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42, \n",
    "                            objective='binary:logistic', eval_metric='logloss', use_label_encoder=False)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "xgb_pred = xgb_clf.predict(X_test)\n",
    "print(f\"XGBoost 정확도: {accuracy_score(y_test, xgb_pred):.3f}\") # 0.956\n",
    "\n",
    "# 4. LightGBM\n",
    "# !pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "lgbm_clf = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "lgbm_clf.fit(X_train, y_train)\n",
    "lgbm_pred = lgbm_clf.predict(X_test)\n",
    "print(f\"LightGBM 정확도: {accuracy_score(y_test, lgbm_pred):.3f}\") # 0.956\n",
    "\n",
    "# 5. 조기 종료(Early Stopping) 기능 활용 (XGBoost 예시)\n",
    "# 검증 세트 준비\n",
    "X_train_sub, X_val, y_train_sub, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "xgb_clf_early = xgb.XGBClassifier(n_estimators=1000, learning_rate=0.05, random_state=42,\n",
    "                                  objective='binary:logistic', eval_metric='logloss', use_label_encoder=False)\n",
    "# early_stopping_rounds: 검증 성능이 향상되지 않아도 기다릴 반복 횟수\n",
    "# eval_set: 성능 평가에 사용할 검증 세트\n",
    "xgb_clf_early.fit(X_train_sub, y_train_sub, \n",
    "                  eval_set=[(X_val, y_val)], \n",
    "                  early_stopping_rounds=100, \n",
    "                  verbose=False) # verbose=True로 하면 학습 과정 출력\n",
    "\n",
    "early_pred = xgb_clf_early.predict(X_test)\n",
    "early_pred_proba = xgb_clf_early.predict_proba(X_test)[:, 1]\n",
    "print(f\"\\nXGBoost (Early Stopping) 정확도: {accuracy_score(y_test, early_pred):.3f}\") # 0.939\n",
    "print(f\"XGBoost (Early Stopping) AUC: {roc_auc_score(y_test, early_pred_proba):.3f}\") # 0.990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e08292d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 가우시안 나이브 베이즈 모델 평가 ---\n",
      "정확도: 0.911\n",
      "\n",
      "혼동 행렬:\n",
      " [[15  0  0]\n",
      " [ 0 14  1]\n",
      " [ 0  3 12]]\n",
      "\n",
      "분류 리포트:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       0.82      0.93      0.87        15\n",
      "           2       0.92      0.80      0.86        15\n",
      "\n",
      "    accuracy                           0.91        45\n",
      "   macro avg       0.92      0.91      0.91        45\n",
      "weighted avg       0.92      0.91      0.91        45\n",
      "\n",
      "\n",
      "클래스별 사전 확률 (priors): [0.33333333 0.33333333 0.33333333]\n",
      "클래스별 특성의 평균 (theta): [[4.98857143 3.42571429 1.48571429 0.24      ]\n",
      " [5.94857143 2.73142857 4.23714286 1.30857143]\n",
      " [6.68285714 3.00857143 5.63142857 2.06857143]]\n",
      "클래스별 특성의 분산 (sigma): [[0.10329796 0.17391021 0.02293878 0.00925715]\n",
      " [0.24078368 0.08558368 0.21147755 0.03564082]\n",
      " [0.42484898 0.11735511 0.32272653 0.06386939]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n[[0.10329796 0.17391021 0.02293878 0.00925715]\\n [0.24078368 0.08558368 0.21147755 0.03564082]\\n [0.42484898 0.11735511 0.32272653 0.06386939]]\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 1. 데이터 준비\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# 2. 가우시안 나이브 베이즈 모델 학습\n",
    "# GaussianNB 주요 하이퍼파라미터\n",
    "# priors: 각 클래스의 사전 확률. None이면 데이터에 따라 자동 계산.\n",
    "# var_smoothing: 분산 계산 시 안정성을 위해 더해주는 작은 값. (기본값=1e-9)\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "\n",
    "# 3. 예측 및 평가\n",
    "y_pred = gnb_clf.predict(X_test)\n",
    "y_pred_proba = gnb_clf.predict_proba(X_test)\n",
    "\n",
    "print(\"--- 가우시안 나이브 베이즈 모델 평가 ---\")\n",
    "print(f\"정확도: {accuracy_score(y_test, y_pred):.3f}\") # 0.911\n",
    "print(\"\\n혼동 행렬:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n분류 리포트:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# 4. 학습된 파라미터 확인\n",
    "print(\"\\n클래스별 사전 확률 (priors):\", gnb_clf.class_prior_) # [0.33333333 0.33333333 0.33333333]\n",
    "print(\"클래스별 특성의 평균 (theta):\", gnb_clf.theta_)\n",
    "print(\"클래스별 특성의 분산 (sigma):\", gnb_clf.sigma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "709ec564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting 정확도: 0.977\n",
      "Soft Voting 정확도: 0.953\n",
      "\n",
      "Logistic Regression 정확도: 0.988\n",
      "KNN 정확도: 0.959\n",
      "SVC 정확도: 0.953\n",
      "Decision Tree 정확도: 0.924\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 개별 모델 임포트\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 앙상블 모델 임포트\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. 데이터 준비 및 전처리\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# 스케일링 (로지스틱 회귀, KNN, SVC에 필요)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 2. 개별 모델 정의\n",
    "# SVC는 probability=True로 설정해야 soft voting 가능\n",
    "lr_clf = LogisticRegression(solver='liblinear', random_state=42)\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "svc_clf = SVC(kernel='rbf', C=10, gamma=0.1, probability=True, random_state=42)\n",
    "dt_clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "\n",
    "# 3. 보팅 분류기 생성\n",
    "# Hard Voting\n",
    "# estimators: (모델 이름, 모델 객체)의 리스트\n",
    "# voting: 'hard' 또는 'soft'\n",
    "hard_voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', lr_clf), ('knn', knn_clf), ('svc', svc_clf), ('dt', dt_clf)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "# Soft Voting\n",
    "soft_voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', lr_clf), ('knn', knn_clf), ('svc', svc_clf), ('dt', dt_clf)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# 4. 모델 학습 및 평가\n",
    "# VotingClassifier는 내부적으로 각 모델에 데이터를 전달하므로, 스케일링된 데이터를 사용\n",
    "hard_voting_clf.fit(X_train_scaled, y_train)\n",
    "hard_pred = hard_voting_clf.predict(X_test_scaled)\n",
    "print(f\"Hard Voting 정확도: {accuracy_score(y_test, hard_pred):.3f}\") # 0.977\n",
    "\n",
    "soft_voting_clf.fit(X_train_scaled, y_train)\n",
    "soft_pred = soft_voting_clf.predict(X_test_scaled)\n",
    "print(f\"Soft Voting 정확도: {accuracy_score(y_test, soft_pred):.3f}\") # 0.953\n",
    "\n",
    "# 개별 모델 성능과 비교\n",
    "lr_clf.fit(X_train_scaled, y_train)\n",
    "lr_pred = lr_clf.predict(X_test_scaled)\n",
    "print(f\"\\nLogistic Regression 정확도: {accuracy_score(y_test, lr_pred):.3f}\") # 0.988\n",
    "\n",
    "knn_clf.fit(X_train_scaled, y_train)\n",
    "knn_pred = knn_clf.predict(X_test_scaled)\n",
    "print(f\"KNN 정확도: {accuracy_score(y_test, knn_pred):.3f}\") # 0.959\n",
    "\n",
    "svc_clf.fit(X_train_scaled, y_train)\n",
    "svc_pred = svc_clf.predict(X_test_scaled)\n",
    "print(f\"SVC 정확도: {accuracy_score(y_test, svc_pred):.3f}\") # 0.953\n",
    "\n",
    "# 결정 트리는 스케일링이 필요 없지만, 비교를 위해 스케일링된 데이터로 학습\n",
    "dt_clf.fit(X_train_scaled, y_train)\n",
    "dt_pred = dt_clf.predict(X_test_scaled)\n",
    "print(f\"Decision Tree 정확도: {accuracy_score(y_test, dt_pred):.3f}\") # 0.924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8fd027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9604cf78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96615b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4debc8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa235ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f8cb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6b671b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0978eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c41f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0579f9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d79d2b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec6f7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c25d935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761bd824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c539f126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
