# 스케일링: StandardScaler, MinMaxScaler, RobustScaler

## 개념 요약

스케일링(Scaling)은 여러 변수(feature)들의 값의 범위를 일정한 수준으로 맞추는 작업을 의미합니다. 많은 머신러닝 알고리즘들은 변수들의 스케일에 민감하기 때문에, 스케일링은 모델의 성능을 향상시키는 데 중요한 전처리 과정입니다. 예를 들어, '나이'(0~100)와 '소득'(0~1,000,000,000) 변수를 함께 사용하면, 소득 변수가 모델에 훨씬 더 큰 영향을 미치게 될 수 있습니다. 스케일링은 이러한 문제를 방지합니다.

`scikit-learn`은 다양한 스케일러를 제공합니다:

- **`StandardScaler` (표준화)**: 각 변수의 평균을 0, 표준편차를 1로 변환합니다. 이는 데이터가 정규분포를 따른다고 가정하며, 각 데이터 포인트가 평균으로부터 몇 표준편차만큼 떨어져 있는지를 나타내는 Z-score와 같습니다.

- **`MinMaxScaler` (정규화)**: 각 변수의 최소값을 0, 최대값을 1로 변환합니다. 모든 데이터가 0과 1 사이의 값으로 맞춰집니다.

- **`RobustScaler`**: `StandardScaler`와 유사하지만, 평균과 표준편차 대신 중앙값(median)과 사분위 범위(IQR)를 사용하여 스케일링합니다. 따라서 이상치(outlier)의 영향을 훨씬 덜 받으며, 이상치가 많은 데이터에 더 적합합니다.

## 적용 가능한 상황

- **변수 간 스케일 차이가 클 때**: 거리 기반 알고리즘(KNN, SVM, K-Means 등), 경사 하강법 기반 알고리즘(선형 회귀, 로지스틱 회귀, 신경망 등)에서 모델이 변수들의 스케일 차이에 영향을 받지 않도록 하기 위해 필수적으로 사용됩니다.

- **`StandardScaler`**: 데이터가 정규분포에 가깝고, 이상치가 거의 없을 때 가장 일반적으로 사용됩니다.

- **`MinMaxScaler`**: 모든 변수를 동일한 범위(0~1)에 놓고 비교하고 싶을 때, 또는 이미지 처리에서 픽셀 값을 0~1 사이로 맞추거나, 신경망 모델에 데이터를 입력할 때 유용합니다.

- **`RobustScaler`**: 데이터에 이상치가 많아 `StandardScaler`의 성능이 저하될 우려가 있을 때 사용하면 더 안정적인 스케일링 결과를 얻을 수 있습니다.

*Note: 트리 기반 모델(Decision Tree, Random Forest, Gradient Boosting 등)은 변수를 독립적으로 처리하므로 일반적으로 스케일링이 필요하지 않습니다.*

## 구현 방법

### 예제 데이터 생성

```python
import pandas as pd
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler

# 소득과 나이, 그리고 이상치를 포함한 데이터 생성
data = {'income': [50000, 52000, 48000, 150000, 51000, 49000, 1000000],
        'age': [25, 30, 28, 45, 26, 27, 35]}
df = pd.DataFrame(data)
```

### 스케일러 적용 원칙

**매우 중요**: 스케일러는 **학습 데이터(train data)에 대해서만 `fit()`과 `transform()`을 적용**하고, **테스트 데이터(test data)에 대해서는 `transform()`만 적용**해야 합니다. 이는 테스트 데이터의 정보(평균, 최소/최대 등)가 모델 학습 과정에 미리 노출되는 것을 방지(Data Leakage)하기 위함입니다. `fit()`은 스케일링에 필요한 통계량(평균, 표준편차, 최소/최대 등)을 계산하는 과정이고, `transform()`은 이를 적용하여 실제로 데이터를 변환하는 과정입니다.

### 1. `StandardScaler`

- **용도**: 평균 0, 표준편차 1을 갖도록 데이터를 변환합니다.
- **수식**: `x_scaled = (x - mean) / std`
- **코드 예시**:
  ```python
  # 1. 스케일러 객체 생성
  scaler_std = StandardScaler()

  # 2. 데이터에 fit_transform 적용 (fit과 transform을 동시에)
  df_std = scaler_std.fit_transform(df)

  # 결과 확인 (Numpy 배열로 반환됨)
  print("--- StandardScaler Result ---")
  print(df_std)
  print(f"\nMean: {df_std.mean(axis=0)}")
  print(f"Std: {df_std.std(axis=0)}")
  ```
- **결과 해석**: 변환된 데이터의 평균은 거의 0에 가깝고, 표준편차는 1이 됩니다. `income`의 이상치(1,000,000) 때문에 다른 값들이 모두 음수로 크게 밀려나는 것을 볼 수 있습니다. 이는 `StandardScaler`가 이상치에 민감함을 보여줍니다.

### 2. `MinMaxScaler`

- **용도**: 최소값 0, 최대값 1을 갖도록 데이터를 변환합니다.
- **수식**: `x_scaled = (x - min) / (max - min)`
- **코드 예시**:
  ```python
  # 1. 스케일러 객체 생성
  scaler_minmax = MinMaxScaler()

  # 2. 데이터에 fit_transform 적용
  df_minmax = scaler_minmax.fit_transform(df)

  # 결과 확인
  print("--- MinMaxScaler Result ---")
  print(df_minmax)
  print(f"\nMin: {df_minmax.min(axis=0)}")
  print(f"Max: {df_minmax.max(axis=0)}")
  ```
- **결과 해석**: 모든 값이 0과 1 사이로 변환됩니다. 하지만 `income`의 이상치(1,000,000)가 1이 되고, 나머지 값들은 0에 매우 가깝게 압축되어 데이터의 분포를 제대로 표현하지 못하게 됩니다. `MinMaxScaler` 역시 이상치에 매우 민감합니다.

### 3. `RobustScaler`

- **용도**: 중앙값 0, IQR 1을 갖도록 데이터를 변환합니다.
- **수식**: `x_scaled = (x - median) / IQR`
- **코드 예시**:
  ```python
  # 1. 스케일러 객체 생성
  scaler_robust = RobustScaler()

  # 2. 데이터에 fit_transform 적용
  df_robust = scaler_robust.fit_transform(df)

  # 결과 확인
  print("--- RobustScaler Result ---")
  print(df_robust)
  ```
- **결과 해석**: `income`의 이상치(1,000,000)가 다른 값들에 미치는 영향이 `StandardScaler`나 `MinMaxScaler`에 비해 훨씬 적습니다. 이상치를 제외한 나머지 값들의 스케일이 비교적 잘 유지되는 것을 볼 수 있습니다. 이처럼 `RobustScaler`는 이상치가 존재할 때 훨씬 안정적인 변환 결과를 제공합니다.

## 장단점 및 대안

| 스케일러 | 장점 | 단점 | 선택 가이드 |
|---|---|---|---|
| **`StandardScaler`** | 가장 널리 사용되는 기본적인 스케일링 방법. 데이터의 분포를 크게 왜곡하지 않음. | 이상치에 매우 민감하여, 이상치가 있는 경우 데이터 분포가 크게 왜곡될 수 있음. | 데이터에 이상치가 거의 없고, 분포가 정규분포에 가까울 때 좋은 선택입니다. 많은 머신러닝 알고리즘의 기본 스케일러로 사용됩니다. |
| **`MinMaxScaler`** | 모든 값을 0과 1 사이로 명확하게 제한함. | 이상치에 매우 민감함. 이상치 하나 때문에 대부분의 데이터가 매우 좁은 범위에 압축될 수 있음. | 데이터의 최소/최대값을 명확히 알고 있고, 그 범위가 크게 변하지 않을 때 유용합니다. 신경망에서 활성화 함수(e.g., Sigmoid)의 입력 범위와 맞출 때 자주 사용됩니다. |
| **`RobustScaler`** | 이상치에 거의 영향을 받지 않아 안정적임(Robust). | `StandardScaler`에 비해 널리 사용되지는 않음. 변환된 값의 범위가 특정 범위로 제한되지 않음. | 데이터에 이상치가 많다고 판단될 때 가장 먼저 고려해야 할 스케일러입니다. 이상치를 제거하지 않고 모델링을 진행할 때 특히 유용합니다. |

**대안**: `MaxAbsScaler`는 각 변수를 최대 절대값으로 나누어 -1과 1 사이로 스케일링합니다. 데이터가 0을 중심으로 분포할 때 유용합니다. `Normalizer`는 각 샘플(행)의 유클리드 길이가 1이 되도록 스케일링하며, 이는 변수(열) 단위로 스케일링하는 다른 방법들과는 다릅니다.

```