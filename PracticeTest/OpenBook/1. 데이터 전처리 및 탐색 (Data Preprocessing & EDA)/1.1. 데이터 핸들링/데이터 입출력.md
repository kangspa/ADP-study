# 데이터 입출력

## 개념 요약

데이터 분석의 첫 단계는 다양한 소스로부터 데이터를 불러오고(Input), 분석이 완료된 결과를 저장하는(Output) 것입니다. Pandas 라이브러리는 CSV, Excel, SQL, JSON 등 다양한 파일 형식을 손쉽게 다룰 수 있는 강력한 입출력 기능들을 제공합니다.

- **`read_csv`**: 쉼표로 구분된 값(Comma-Separated Values) 형식의 텍스트 파일을 읽어 Pandas DataFrame으로 변환하는 가장 일반적인 함수입니다.
- **`read_excel`**: Microsoft Excel 파일(`.xls`, `.xlsx`)을 읽어 DataFrame으로 변환합니다. 특정 시트(sheet)를 지정하거나 여러 시트를 한 번에 불러올 수 있습니다.
- **`to_csv`**: DataFrame을 CSV 파일로 저장합니다. 인덱스 저장 여부, 구분자 지정 등 다양한 옵션을 제공합니다.

## 적용 가능한 상황

- **`read_csv`**: 
    - 대부분의 정형 데이터가 저장되고 공유되는 표준 형식인 CSV 파일을 다룰 때.
    - 탭(TSV), 세미콜론 등 다른 구분자로 분리된 텍스트 파일을 읽을 때 (`sep` 인자 활용).
    - 대용량 파일을 다룰 때, 특정 열만 선택하거나(`usecols`), 정해진 행의 개수만큼만 읽어(`nrows`) 메모리를 효율적으로 사용해야 할 때.

- **`read_excel`**: 
    - 비즈니스 환경에서 생성된 Excel 보고서나 데이터를 분석해야 할 때.
    - 하나의 Excel 파일 내에 여러 시트로 데이터가 나뉘어 저장되어 있을 때.

- **`to_csv`**: 
    - 전처리나 분석이 완료된 DataFrame을 다른 시스템이나 소프트웨어에서 사용하기 위해 CSV 형식으로 내보낼 때.
    - 분석 결과를 저장하여 나중에 다시 사용하거나 공유해야 할 때.

## 구현 방법

### 1. `read_csv`

- **용도**: CSV 또는 기타 구분자로 분리된 텍스트 파일을 DataFrame으로 불러옵니다.
- **주의사항**: 파일 경로, 인코딩 문제, 구분자 불일치로 인해 에러가 발생할 수 있습니다. 대용량 파일의 경우 모든 데이터를 메모리에 한 번에 올리면 문제가 될 수 있으므로, `chunksize`나 `iterator` 인자를 사용하여 단계적으로 처리하는 것이 좋습니다.
- **코드 예시**:
  ```python
  import pandas as pd
  import io

  # 예제 CSV 데이터 생성
  csv_data = "col1,col2,col3\n1,a,True\n2,b,False\n3,c,True"

  # 문자열 데이터를 파일처럼 읽기 위해 io.StringIO 사용
  # 실제 파일 경로를 사용할 경우: pd.read_csv('path/to/your/file.csv')
  df_csv = pd.read_csv(io.StringIO(csv_data))
  print(df_csv)
  ```
- **결과 해석**:
  ```
     col1 col2   col3
  0     1    a   True
  1     2    b  False
  2     3    c   True
  ```
  CSV 형식의 텍스트 데이터가 성공적으로 DataFrame으로 변환되었습니다. 각 열은 데이터 타입이 자동으로 추론됩니다 (`col1`: int64, `col2`: object, `col3`: bool).

- **주요 하이퍼파라미터 (인자)**:
    - `filepath_or_buffer`: 파일 경로(문자열), URL 또는 파일과 유사한 객체.
    - `sep` (또는 `delimiter`): 필드를 구분하는 데 사용될 구분자. 기본값은 `,` (쉼표)입니다. 탭으로 구분된 파일(TSV)의 경우 `'	'`로 지정합니다.
    - `header`: 헤더로 사용할 행의 번호. 기본값은 `0` (첫 번째 행)이며, 헤더가 없는 경우 `None`으로 지정합니다.
    - `names`: 헤더가 없을 때(`header=None`) 사용할 열 이름의 리스트.
    - `index_col`: 인덱스로 사용할 열의 번호나 이름.
    - `usecols`: 읽어올 열의 이름이나 인덱스 리스트. 메모리 사용량을 줄이고 로딩 속도를 높이는 데 유용합니다.
    - `dtype`: 열별로 데이터 타입을 지정하는 딕셔너리. (e.g., `{'col1': str, 'col2': float}`)
    - `encoding`: 파일 인코딩 형식. 한글이 포함된 파일의 경우 `'utf-8'` 또는 `'cp949'` 등을 시도해야 할 수 있습니다.
    - `nrows`: 읽어올 파일의 행 수. 파일의 구조를 빠르게 확인하거나, 큰 파일의 일부만 샘플링할 때 유용합니다.
    - `na_values`: 특정 값을 결측치(NaN)로 처리하도록 지정합니다. (e.g., `['N/A', '?']`)

### 2. `read_excel`

- **용도**: Excel 파일을 DataFrame으로 불러옵니다.
- **주의사항**: `read_excel`을 사용하려면 `openpyxl`(for `.xlsx`) 또는 `xlrd`(for `.xls`) 라이브러리가 설치되어 있어야 합니다. (`pip install openpyxl xlrd`)
- **코드 예시**:
  ```python
  import pandas as pd
  import io

  # read_excel은 바이트 스트림을 필요로 하므로, 예제 생성을 위해 BytesIO 사용
  # 실제 파일 경로 사용 시: pd.read_excel('path/to/your/file.xlsx')
  output = io.BytesIO()
  with pd.ExcelWriter(output, engine='openpyxl') as writer:
      df = pd.DataFrame({"col1": [1, 2], "col2": [0.5, 0.75]})
      df.to_excel(writer, index=False, sheet_name='Sheet1')
  
  # BytesIO의 포인터를 처음으로 되돌림
  output.seek(0)

  df_excel = pd.read_excel(output, sheet_name='Sheet1')
  print(df_excel)
  ```
- **결과 해석**:
  ```
     col1  col2
  0     1  0.50
  1     2  0.75
  ```
  Excel 파일의 'Sheet1'에 저장된 데이터가 DataFrame으로 성공적으로 로드되었습니다.

- **주요 하이퍼파라미터 (인자)**:
    - `io`: 파일 경로, URL 또는 Excel 파일 객체.
    - `sheet_name`: 읽어올 시트의 이름(문자열)이나 번호(0부터 시작). 기본값은 `0` (첫 번째 시트)입니다. 모든 시트를 읽으려면 `None`으로 지정하면, 시트 이름을 키로 갖는 딕셔너리가 반환됩니다.
    - `header`: 헤더로 사용할 행의 번호. 기본값은 `0`.
    - `names`: 헤더가 없을 때 사용할 열 이름 리스트.
    - `index_col`: 인덱스로 사용할 열의 번호.
    - `usecols`: 읽어올 열의 범위 (e.g., `'A:C'`) 또는 리스트.
    - `engine`: 사용할 파서 엔진. `.xlsx`는 `'openpyxl'`, `.xls`는 `'xlrd'`가 주로 사용됩니다.

### 3. `to_csv`

- **용도**: DataFrame을 CSV 파일로 저장합니다.
- **주의사항**: 기본적으로 행 인덱스가 파일에 포함됩니다. 인덱스를 제외하고 싶다면 `index=False` 옵션을 반드시 사용해야 합니다. 파일 경로에 해당하는 폴더가 미리 존재해야 합니다.
- **코드 예시**:
  ```python
  import pandas as pd

  df = pd.DataFrame({'Name': ['Alice', 'Bob'], 'Age': [25, 30]})

  # 파일로 저장 (인덱스 제외, UTF-8 인코딩)
  # df.to_csv('output.csv', index=False, encoding='utf-8')

  # 문자열로 결과 확인
  csv_output = df.to_csv(index=False)
  print(csv_output)
  ```
- **결과 해석**:
  ```
  Name,Age
  Alice,25
  Bob,30
  ```
  DataFrame이 쉼표로 구분된 CSV 형식의 문자열로 변환되었습니다. `index=False`로 지정하여 불필요한 인덱스 열이 저장되지 않았습니다.

- **주요 하이퍼파라미터 (인자)**:
    - `path_or_buf`: 저장할 파일 경로 또는 버퍼. 지정하지 않으면 문자열로 결과를 반환합니다.
    - `sep`: 사용할 필드 구분자. 기본값은 `,`.
    - `na_rep`: 결측치(NaN)를 나타낼 문자열. 기본값은 빈 문자열.
    - `columns`: 파일에 쓸 열을 선택하는 리스트.
    - `header`: 열 이름을 쓸지 여부. 기본값은 `True`.
    - `index`: 행 인덱스를 쓸지 여부. 기본값은 `True`이며, 보통 `False`로 설정하여 불필요한 열 생성을 방지합니다.
    - `encoding`: 파일 인코딩 형식. 한글 데이터를 포함하는 경우 `'utf-8-sig'`를 사용하면 Excel에서 파일을 열 때 깨짐 현상을 방지할 수 있습니다.

## 장단점 및 대안

| 형식 | 장점 | 단점 | 대안 |
|---|---|---|---|
| **CSV** | 구조가 단순하고, 용량이 작으며, 대부분의 시스템과 호환됨 | 데이터 타입 정보가 저장되지 않음, 복잡한 계층 구조 표현 불가 | **Parquet/Feather**: 데이터 타입 유지, 압축 효율이 뛰어나 대용량 데이터에 적합. `pd.to_parquet`, `pd.read_parquet` 사용. |
| **Excel** | 사용자가 시각적으로 데이터를 확인하고 편집하기 편리함, 여러 시트 지원 | 대용량 파일 처리 시 매우 느리고 비효율적, 바이너리 포맷이라 버전 문제 발생 가능 | CSV (단순 데이터 저장), 데이터베이스 (대용량 데이터 관리), Parquet (분석용 데이터 저장) |
| **기타** | | | **JSON**: `pd.read_json`, `pd.to_json`. 웹 API 등에서 많이 사용하는 반정형 데이터 형식. <br> **SQL**: `pd.read_sql`, `pd.to_sql`. 데이터베이스와 직접 연동하여 데이터를 읽고 쓸 수 있음. `SQLAlchemy`와 같은 라이브러리 필요. |
