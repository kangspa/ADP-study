# 데이터 조작

## 적용 가능한 상황

- **변수 선택**: 분석에 필요한 변수(열)만 선택하거나, 불필요한 변수를 제거할 때.
- **데이터 클리닝**: 특정 조건을 만족하는 이상치를 제거하거나, 잘못 입력된 값을 수정할 때.
- **파생 변수 생성**: 기존 변수들을 조합하여 새로운 의미를 갖는 변수(열)를 만들 때. (e.g., '키'와 '몸무게'로 'BMI'를 계산)
- **데이터 정규화**: 범주형 변수를 수치형으로 변환하거나(e.g., '남성'/'여성' -> 0/1), 수치형 변수의 단위를 변경할 때.
- **사용자 정의 함수 적용**: Pandas에서 기본으로 제공하지 않는 복잡한 로직을 데이터의 각 부분에 적용해야 할 때.

## 예제 데이터프레임 생성

```python
import pandas as pd
import numpy as np

data = {'Group': ['A', 'B', 'A', 'B', 'A'],
        'Category': ['X', 'Y', 'X', 'Z', 'Y'],
        'Value1': [10, 20, 30, 40, 50],
        'Value2': ['100', '200', '300', '400', '500']}
df = pd.DataFrame(data)
```

## 1. 행/열 선택 및 변경

- 특정 조건에 맞는 행(row)이나 필요한 열(column)을 추출하고, 값을 새로운 값으로 변경
- `.loc`는 레이블(이름) 기반, `.iloc`는 정수 위치 기반 → 명확히 구분해서 사용 필요
  - 연속되지 않은 여러 행/열을 선택할 때는 리스트 `[]` 사용

```python
# 열 선택
print(df['Value1']) # Series 형태로 반환
'''
0    10
1    20
2    30
3    40
4    50
Name: Value1, dtype: int64
'''
print(df[['Group', 'Value1']]) # DataFrame 형태로 반환
'''
  Group  Value1
0     A      10
1     B      20
2     A      30
3     B      40
4     A      50
'''

# 행 선택 (loc, iloc)
print(df.loc[0]) # 인덱스 레이블이 0인 행
'''
Group         A
Category      X
Value1       10
Value2      100
Name: 0, dtype: object
'''
print(df.iloc[0:2]) # 0, 1번 위치의 행 (2는 포함 안 됨)
'''
  Group Category  Value1 Value2
0     A        X      10    100
1     B        Y      20    200
'''
print(df.loc[[0, 3]]) # 0, 3번 인덱스 레이블의 행
'''
  Group Category  Value1 Value2
0     A        X      10    100
3     B        Z      40    400
'''

# 특정 행/열의 값 선택
print(df.loc[0, 'Value1']) # 10
print(df.at[0, 'Value1']) # 10, 단일 값 선택 시 더 빠름

# 값 변경
df.loc[df['Group'] == 'A', 'Value1'] = 99 # 조건에 맞는 행의 특정 열 값 변경
print(df)
'''
  Group Category  Value1 Value2
0     A        X      99    100
1     B        Y      20    200
2     A        X      99    300
3     B        Z      40    400
4     A        Y      99    500
'''
```
- **결과 확인**: 조건부 필터링과 결합하여 특정 조건을 만족하는 데이터의 값을 효율적으로 변경

## 2. 데이터 타입 변경 (`astype`)

- 분석에 적합한 형태로 열의 데이터의 타입(Dtype)을 변환
- 변환하려는 열에 부적절한 값(e.g., 숫자로 바꿀 열에 문자 포함)이나 결측치(NaN)가 있으면 에러가 발생 가능
  - `pd.to_numeric`의 `errors` 인자를 사용하면 이런 상황을 제어 가능

```python
print(f"Original Dtype of Value2: {df['Value2'].dtype}") # object

# 'Value2' 열을 정수형으로 변경
df['Value2'] = df['Value2'].astype(int)
print(f"New Dtype of Value2: {df['Value2'].dtype}") # int32

# pd.to_numeric 사용 (에러 처리 기능 포함)
s = pd.Series(['1', '2', 'a'])
s_numeric = pd.to_numeric(s, errors='coerce') # 'a'는 NaN으로 변환됨
print(s_numeric)
'''
0    1.0
1    2.0
2    NaN
dtype: float64
'''
```
- **결과 해석**
  - `astype(int)`를 통해 `Value2` 열이 `object`(문자열) 타입에서 `int64`(정수) 타입으로 성공적으로 변환되었습니다.
  - `pd.to_numeric`은 `errors='coerce'` 옵션을 통해 변환 불가능한 값을 강제로 `NaN`으로 만들어주어, 데이터 클리닝 시 유용합니다.

## 3. 필터링 (Boolean Indexing)

- 하나 이상의 조건을 만족하는 데이터 행을 불리언 인덱싱(Boolean Indexing)을 통해 추출
- 여러 조건을 결합할 때는 `&` (AND), `|` (OR) 연산자를 사용하며, 각 조건은 반드시 괄호 `()`로 묶어야 함 (e.g., `(df['A'] > 1) & (df['B'] < 10)`)

```python
# 단일 조건 필터링
df_group_b = df[df['Group'] == 'B']
print(df_group_b)
'''
  Group Category  Value1  Value2
1     B        Y      20     200
3     B        Z      40     400
'''

# 다중 조건 필터링
df_filtered = df[(df['Group'] == 'A') & (df['Value1'] > 20)]
print(df_filtered)
'''
  Group Category  Value1  Value2
0     A        X      99     100
2     A        X      99     300
4     A        Y      99     500
'''

# isin을 사용한 필터링
df_isin = df[df['Category'].isin(['X', 'Y'])]
print(df_isin)
'''
  Group Category  Value1  Value2
0     A        X      99     100
1     B        Y      20     200
2     A        X      99     300
4     A        Y      99     500
'''
```
- **결과 해석**
  - 불리언 시리즈(True/False로 구성된 Series)를 데이터프레임의 인덱서로 사용하면, `True`에 해당하는 행만 선택됩니다.
  - `isin` 메서드는 특정 열의 값이 리스트에 포함된 여러 값 중 하나에 해당하는지 여부를 검사할 때 유용합니다.

## 4. `apply` / `map`

- 데이터에 함수를 일괄적으로 적용
- `apply`는 DataFrame의 행 또는 열 전체에, `map`은 Series의 각 원소에, `applymap`은 DataFrame의 모든 원소에 적용
- 일반적으로 벡터화된 연산(Numpy/Pandas 기본 연산)이 `apply`보다 훨씬 빠르므로, 가능한 한 벡터화 연산을 먼저 고려해야 함

```python
# apply: 열(axis=0) 또는 행(axis=1) 단위로 함수 적용
def get_stats(x):
  return pd.Series([x.min(), x.max(), x.mean()], index=['min', 'max', 'mean'])

# Value1, Value2 열에 대해 통계량 계산
stats_df = df[['Value1', 'Value2']].apply(get_stats)
print(stats_df)
'''
      Value1  Value2
min     20.0   100.0
max     99.0   500.0
mean    71.4   300.0
'''

# apply with lambda (행 단위 연산)
df['Value_Sum'] = df.apply(lambda row: row['Value1'] + row['Value2'], axis=1)
print(df)
'''
  Group Category  Value1  Value2  Value_Sum
0     A        X      99     100        199
1     B        Y      20     200        220
2     A        X      99     300        399
3     B        Z      40     400        440
4     A        Y      99     500        599
'''

# map: Series의 각 원소에 함수 또는 딕셔너리 적용
df['Group_Code'] = df['Group'].map({'A': 1, 'B': 2})
print(df)
'''
  Group Category  Value1  Value2  Value_Sum  Group_Code
0     A        X      99     100        199           1
1     B        Y      20     200        220           2
2     A        X      99     300        399           1
3     B        Z      40     400        440           2
4     A        Y      99     500        599           1
'''
```
- **결과 해석**
  - `apply`를 사용하여 각 열의 최소, 최대, 평균값을 계산했습니다.
  - `lambda` 함수와 `apply(axis=1)`를 조합하여 각 행의 `Value1`과 `Value2`를 더한 새로운 열 `Value_Sum`을 생성했습니다.
  - `map`을 사용하여 `Group` 열의 문자열 값('A', 'B')을 숫자(1, 2)로 매핑하는 '인코딩' 작업을 수행했습니다.

## 장단점 및 대안

| 기능 | 장점 | 단점 | 대안/팁 |
|---|---|---|---|
| **행/열 선택** | `.loc`, `.iloc`를 통해 명시적이고 유연한 선택 가능 | 문법이 다소 복잡하고, 초보자가 실수하기 쉬움 (`SettingWithCopyWarning`) | 단일 값 접근에는 `at`, `iat`이 더 빠름. 열 선택 시 `df.Value1`과 같은 속성 접근도 가능하지만, 공백이나 특수문자가 있는 열 이름에는 사용할 수 없어 `df['Value1']` 방식이 더 안전함. |
| **`astype`** | 간단한 문법으로 데이터 타입을 쉽게 변경 가능 | 변환 불가능한 값이 있을 경우 에러 발생 | `pd.to_numeric`, `pd.to_datetime`, `pd.to_timedelta` 등 특정 타입 변환에 특화된 함수들은 `errors` 인자를 통해 더 정교한 에러 처리가 가능함. |
| **필터링** | 직관적이고 강력한 조건 기반 데이터 추출 | 여러 조건을 중첩할 때 괄호 사용을 잊기 쉬움 | 복잡한 조건은 변수로 분리하여 가독성을 높일 수 있음. `df.query('Group == "A" and Value1 > 20')`는 문자열 형태로 쿼리를 작성하여 더 간결하게 필터링할 수 있는 대안임. |
| **`apply`/`map`** | 복잡하고 사용자 정의된 로직을 쉽게 적용 가능 | 벡터화된 연산에 비해 속도가 매우 느림 | 가능한 한 `+`, `*` 와 같은 기본 연산자나, `np.log()`, `str.lower()` 등 Pandas/Numpy에 내장된 벡터화 함수를 먼저 사용해야 함. `map`은 딕셔너리를 인자로 받을 수 있어 인코딩에 매우 효율적임. |