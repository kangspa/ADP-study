# 하둡(Hadoop)

- **대규모 분산 병렬 처리**의 업계 표준인 **맵리듀스(MapReduce) 시스템과 분산 파일 시스템인 HDFS(하둡 파일 시스템)를 핵심 구성요소로 가지는 플랫폼 기술**이다.
- 여러 대의 컴퓨터를 하나의 시스템인 것처럼 통합한 분산 환경에서 빅데이터를 저장 및 처리 할 수 있도록 하는 자바 기반 오픈소스 프레임워크다.
- **비공유 분산 아키텍처**를 사용한다.

## 특징

### 선형적인 성능과 용량 확장

- 이론적으로 클러스터를 구성할 수 있는 서버의 대수는 제한이 없지만, 보통 최소 5대 정도로 구성한다.
- 연산 기능과 저장 기능이 **서버의 대수에 비례**해 증가하는 **비공유 분산 아키텍처 시스템**이다.

### 고장 감내성 (Fault Tolerance)

- HDFS에 저장되는 데이터는 **3중 복제**가 되어 서로 다른 물리서버에 저장되므로, 서버에 장애가 발생하더라도 데이터 유실을 방지할 수 있다.
- 장애 발생 시, 시스템이 자동으로 감지해 **장애가 발생한 특정 태스크만 다른 서버에서 재실행** 할 수 있다.

### 핵심 비즈니스 로직에만 집중

- **맵(Map)과 리듀스(Reduce)**라는 2개 함수만 구현하면서 동작하는 시스템
- 비즈니스 로직에만 집중할 수 있도록, 시스템 수준에서 발생하는 장애에 대해 자동 복구(Failover)를 제공하고, 확장성 및 성능 등의 이슈도 하둡이 내부적으로 최적화해 처리한다.

### 하둡 에코 시스템 (Hadoop Ecosystem)

- 하둡 프레임워크를 이루고 있는 다양한 서브 프로젝트들의 집합이다.
- 비정형 데이터 수집, 정형 데이터 수집, 분산 데이터 저장, 분산 데이터베이스, 분산 데이터 처리, 리소스 관리, 인메모리 처리, 데이터 가공, 데이터 마이닝, 실시간 SQL 질의, 워크플로우 관리, 분산 코디네이션 등

## 하둡 에코 시스템 기술들

### 비정형 데이터 수집

- 척와(Chukwa) : 분산된 각 서버에서 에이전트 실행, 컬렉터가 에이전트로부터 데이터를 받아 HDFS에 저장하는 기술
- 플럼(Flume) : 많은 양의 로그 데이터를 효율적으로 수집, 집계 이동하기 위해 이벤트와 에이전트를 활용하는 기술
- 스크라이브(Scribe) : 다수의 서버로부터 실시간 스트리밍되는 로그 데이터를 수집하여 분산 시스템에 데이터를 저장하는 대용량 실시간 로그 수집 기술

### 정형 데이터 수집

- 스쿱(Sqoop) : 대용량 데이터 전송 솔루션으로 데이터 연동 기능을 수행
    - JDBC를 지원하는 대부분의 관계형 데이터베이스와의 연동을 지원
    - HBase와 같은 일부 NoSQL 데이터베이스와도 연동 가능
    - 맵 인풋 포맷터를 사용하며, SQL을 통해 테이블에서 데이터 추출
    - 데이터의 이동을 맵리듀스를 이용해서 처리한다.
    - 장애 허용 능력과 병렬 처리 기능을 제공한다.
    - Import 명령어 : RDBMS → HDFS
    - Export 명령어 : HDFS → RDBMS
- 히호(Hiho) : 대용량 데이터 전송 솔루션이며, 하둡에서 데이터를 가져오기 위한 SQL을 지정할 수 있으며, JDBC 인터페이스를 지원

### 분산 데이터 저장

- HDFS : 대용량 파일을 분산된 서버에 저장하고, 그 데이터를 빠르게 처리할 수 있게 하는 하둡 분산 파일 시스템이다.
    - 범용 하드웨어 기반 클러스터에서 실행되고 데이터 접근 패턴을 스트리밍 방식으로 지원하며, 다중 복제, 대량 파일 저장, 온라인 변경, 범용 서버 기반, 자동 복구 특징을 갖는다.
    - 구성 요소
        - 네임노드 : 마스터 역할, 모든 메타데이터 관리, 데이터노드들로부터 하트비트를 받아 상태 체크
        - 보조 네임노드 : 상태 모니터링을 보조
        - 데이터노드 : 슬레이브 역할, 데이터 입출력 요청, 유실방지를 위해 블록을 3중 복제

### 분산 데이터베이스

- HBase : HDFS를 기반으로 구현된 컬럼 기반의 분산 데이터베이스
    - 실시간 랜덤 조회 및 업데이트를 할 수 있으며, 각각의 프로세스는 개인의 데이터를 비동기적으로 업데이트 할 수 있다.

### 분산 데이터 처리

- 맵리듀스(MapReduce) : 대용량 데이터 세트를 분산 병렬 컴퓨팅에서 처리하거나 생성하기 위해 만들어진 소프트웨어 프레임워크로, 모든 데이터를 키-값(Key-Value) 쌍으로 구성된다.
    - 구성 요소
        - 맵(Map) : Key-Value 형태로 데이터를 취합
        - 셔플(Shuffle) : 데이터를 통합하여 처리
        - 리듀스(Reduce) : 맵 처리된 데이터를 정리

### 리소스 관리

- 얀(YARN) : 하둡의 맵리듀스 처리 부분을 새롭게 만든 자원 관리 플랫폼
    - 구성 요소
        - 리소스 매니저 : 스케줄러 역할을 수행, 클러스터 이용률 최적화 수행
        - 노드 매니저 : 노드 내 자원을 관리하고, 리소스 매니저에게 전달 수행 및 컨테이너를 관리
        - 애플리케이션 마스터 : 리소스 매니저와 자원의 교섭을 책입지고, 컨테이너를 실행
        - 컨테이너 : 프로그램 구동을 위한 격리 환경을 지원하는 가상화 자원

### 인메모리 관리

- 아파치 스파크(Apache Spark) : 하둡 기반 대규모 데이터 분산처리시스템
    - 스트리밍 데이터, 온라인 머신러닝 등 실시간으로 데이터를 처리한다.

### 데이터 가공

- 피그(Pig) : 대용량 데이터 집합을 분석하기 위한 플랫폼
    - 하둡을 이용하여 맵리듀스를 사용하기 위한 높은 수준의 스크립트 언어인 피그 라틴이라는 자체 언어를 제공한다.
- 하이브(Hive) : 하둡 기반 DW 솔루션
    - SQL과 매우 유사한 HiveQL이라는 쿼리 제공
    - 사용자가 하둡에 저장된 데이터를 쉽게 처리하고 분석하기 위해 등장

### 데이터 마이닝

- 머하웃(Mahout) : 하둡 기반으로 데이터 마이닝 알고리즘을 구현한 오픈소스
    - 분류, 클러스터링, 추천 및 협업 필터링, 패턴 마이닝, 회귀 분석, 진화 알고리즘 등 주요 알고리즘을 지원

### 실시간 SQL 질의

- 임팔라(Impala) : 하둡 기반 실시간 SQL 질의 시스템
    - 데이터 조회를 위한 인터페이스로 HiveQL을 사용하며, 수초 내에 SQL 질의 결과를 확인할 수 있으며, HBase와 연동이 가능하다.
    - 하둡 전문 회사인 클라우데라(Cloudera)에서 개발 주도
- 타조(Tajo) : 다양한 데이터 소스를 위한 하둡 기반 ETL 기술을 이용해서 DW에 적재하는 시스템
    - 고려대 대학원에서 시작된 프로젝트
    - 국내 빅데이터 전문회사인 그루터(Gruter)가 합류하여 개발 진행
    - 아파치 인큐베이션 프로젝트로 등록되어 있음

### 워크플로우 관리

- 우지(Oozie) : 하둡 작업을 관리하는 워크플로우 및 코디네이터 시스템

### 분산 코디네이션

- 주키퍼(Zookeeper) : 분산 환경에서 서버들 간에 상호 조정이 필요한 다양한 서비스를 제공하는 기술
    - 하나의 서버에서만 서비스가 집중되지 않도록 서비스를 알맞게 분산하여 동시에 처리

# SQL on Hadoop

- 하둡과 하이브는 **대용량 데이터를 배치 처리하는데 최적화** 되어 있지만, 실시간 조회나 처리는 어렵다.
- 실시간 조회 및 처리에 대한 제약을 극복하기 위해 **실시간 SQL 질의 분석** 기술로써 **SQL on 하둡**이 등장하였다.

### 기술 종류

- 아파치 타조(Tajo)
- 임팔라(Impala)
- 아파치 드릴(Drill) : 맵알(MapR)이 주축인 프로젝트로 드레멜의 아키텍처와 기능을 동일하게 구현한 오픈 소스 버전의 드레멜
- 아파치 스팅거(Stinger) : 호튼웍스에서 개발을 주도하고 있으며, 기존의 하이브 코드를 최대한 이용하여 성능을 개선하는 방향으로 진행 중
- 샤크(Shark) : 인메모리 기반의 대용량 DW 시스템이며, 하이브와 호환되기 때문에 하이브 SQL 질의와 사용자 정의 함수를 사용할 수 있음
- 호크(HAWQ) : EMC에서 분사한 피보탈(Pivotal)에서 개발한 프로젝트로, 상용과 커뮤니티 2가지 버전을 제공
- 프레스토 : 페이스북에서 자체적으로 개발하여 사용하고 있는 하둡 기반의 데이터 웨어하우징 엔진이며, 아파치 라이선스로 공개됨